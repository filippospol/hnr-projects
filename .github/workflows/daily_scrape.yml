name: Daily NBA Data Scrape

on:
  schedule:
    - cron: '0 9 * * *' 
  workflow_dispatch:

jobs:
  scrape-data:
    runs-on: ubuntu-22.04 # Pinned to a stable Ubuntu version for reliable R binaries
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: 'release'
          use-public-rspm: true # MAGIC: Downloads lightning-fast pre-compiled packages

      # 1. Install the hidden Linux system tools that packages like tidyverse and rvest need
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev

      # 2. Use standard R installation (no fancy package managers that get confused)
      - name: Install R packages
        run: |
          install.packages(c("tidyverse", "hoopR", "httr", "jsonlite", "rvest", "glue", "janitor", "fuzzyjoin", "plyr"))
        shell: Rscript {0}

      # 3. Run your clean, pacman-free script
      - name: Run scraper script
        run: Rscript hnrdb_full.R

      # 4. Save the data
      - name: Commit and push new data
        run: |
          git config --local user.name "GitHub Actions Bot"
          git config --local user.email "actions@github.com"
          git add *.csv
          git commit -m "Auto-update daily NBA stats" || echo "No changes to commit"
          git push origin main
